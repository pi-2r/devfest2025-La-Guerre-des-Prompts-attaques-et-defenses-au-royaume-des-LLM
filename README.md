# [DevFest 2025] La Guerre des Prompts : attaques & dÃ©fenses au royaume des LLM âš”ï¸ğŸ›¡ï¸ğŸ¤–



ğŸš§ ğŸ‡¬ğŸ‡§ ğŸš§ English version available [here](https://github.com/pi-2r/devfest2025-La-Guerre-des-Prompts-attaques-et-defenses-au-royaume-des-LLM/tree/english-version) ğŸš§ ğŸ‡¬ğŸ‡§ ğŸš§



Ce projet github est issue du workshop fait par [Benjamin Bernard](https://www.linkedin.com/in/benvii/), [Xavier Charef](https://www.linkedin.com/in/xavier-charef-6b843497/), [FranÃ§ois Nollen](https://www.linkedin.com/in/francois-nollen/) et [Pierre Therrode](https://www.linkedin.com/in/ptherrode/), pour le Devfest 2025, avec comme sujet : [La Guerre des Prompts : attaques & dÃ©fenses au royaume des LLM âš”ï¸ğŸ›¡ï¸ğŸ¤–](https://devfest2025.gdgnantes.com/en/sessions/la_guerre_des_prompts___attaques___defenses_au_royaume_des_llm________)

<img src="img/la-guerre-des-prompts-attaques-et-defenses-au-royaume-des-llm.png"  alt="La Guerre des Prompts : attaques & dÃ©fenses au royaume des LLM">


## Info rÃ©seau

Point d'accÃ¨s wifi :
* SSID: LLM_ATTACK
* Mot de passe: password

Lab AI Red Team partagÃ© disponible ici : http://192.168.20.2:5000/login?auth=YOUR_AUTH_KEY

Instance partagÃ©e de Tock disponible ici : http://192.168.20.2/

*Comptes utilisÃ©s pour l'instance partagÃ©e (vous avez un petite papier), sinon [liste ici](https://docs.google.com/spreadsheets/d/1dUkbyRc33teEPK-bCrGTdLKIvyPblk4PbxfZXNg2VFA/edit?usp=sharing).*

## Sommaire

<details>
  <summary>ğŸš§ ğŸ’¡ ğŸš§ note sur La section â€œIntroduction aux menaces de lâ€™IA gÃ©nÃ©rativeâ€ ğŸš§ ğŸ’¡ ğŸš§</summary>
    
La section â€œ**Introduction aux menaces de lâ€™IA gÃ©nÃ©rative**â€ vise avant tout Ã  donner des repÃ¨res pour comprendre les enjeux
et prendre du recul sur le sujet, avant de se lancer pleinnement dans la pratique ("**Comprendre les Principes du Prompt Injection et leurs Impacts**"). 

Lors du codelab, cette introduction sera prÃ©sentÃ©e sous forme de diaporama (environ 10min). Cela permettra Ã  chacun de 
prÃ©parer sereinement sa machine tout en se familiarisant progressivement avec la thÃ©matique abordÃ©e.
</details>


### Introduction aux menaces de l'IA gÃ©nÃ©rative (10 min)
 
- [1 - Il Ã©tait une fois dans un monde numÃ©rique...](step_1.md)
- [2 - Pourquoi la sÃ©curitÃ© des LLM est-elle cruciale ?](step_2.md)
- [3 - Des Ã©carts sous contrÃ´le relatif](step_3.md)
- [4 - Cadres de sÃ©curitÃ© rÃ©fÃ©rents](step_4.md)

### Comprendre les principes du prompt injection (30 min)
 
- [5 - Introduction au playground et objectifs](step_5.md)
- [6 - Techniques d'attaque par prompt injection](step_6.md)
- [7 - Impacts rÃ©els et scÃ©narios d'exploitation](step_7.md)

### Test de robustesse (40 min)

- [8 - Test de robustesse ?](step_8.md)
- [9 - Garak: A Framework for Security Probing Large Language Models](step_9.md)
- [10 - PyRIT: Framework for Security Risk Identification and Red Teaming in Generative AI System](step_10.md)


### Contre-mesures et stratÃ©gies de dÃ©fense (35 min)

- [11 - Mettre en place notre chatbot avec la solution Tock](step_11.md)
- [12 - Mettre en place les premieres contre-mesures avec FastAPI](step_12.md)
- [13 - Mettre en place NeMo Guardrails](step_13.md)


### [BONUS] Ã‰valuation et amÃ©lioration de la robustesse

 - [14 - AI Red Teaming](step_14.md)
 - [15 - Benchmarking avec Promptfoo](step15.md)


### [CONCLUSION] Pour aller plus loin (5 min)

- [Remerciements](thanks-you.md)
- [En savoir plus / ressources](resources.md)
