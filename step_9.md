# Garak: An LLM vulnerability scanner

[<img src="img/minas_tirith_tree_burning.jpg" alt="minas_tirith_burning" width="800" >](https://www.youtube.com/watch?v=yFBrm5YH9-8)
> "A white tree in a courtyard of stone.. It was dead.. The city was burning.", Pippin, LOTR - The Return of the King

## ğŸ¯ Objectifs de cette Ã©tape

- PrÃ©sentation de garak.
- Mettre en pratique ces techniques sur ce Playground de Microsoft : [AI-Red-Teaming-Playground-Labs](https://github.com/microsoft/AI-Red-Teaming-Playground-Labs).

## Sommaire


- [Garak](#prÃ©sentation-de-garak)

    - [PrÃ©sentation de Garak](#prÃ©sentation-de-garak)
    - [Les generators](#les-generators)

- [Mise en pratique de Garak](#mise-en-pratique-de-garak)


## Garak

Garak est un outil open-source dÃ©veloppÃ© par NVIDIA pour scanner les vulnÃ©rabilitÃ©s des modÃ¨les de langage (LLM).
Il est conÃ§u pour identifier les failles de sÃ©curitÃ© potentielles dans les systÃ¨mes utilisant les LLMs.

### PrÃ©sentation de Garak

**Garak** se fonde sur une base de connaissances de jailbreaks prompts connus et constamment mis Ã  jour par la communautÃ©.
Garak permet de faire un scanning automatisÃ© des LLM en utilisant un certain nombre de sondes (probes).
Vous pouvez voir la liste des probes disponibles en exÃ©cutant la commande suivante :

```bash

python -m garak --list_probes
```

Certaines probes sont suivies de symboles ğŸŒŸ ou ğŸ’¤ comme ceci :
```plaintext
probes: divergence ğŸŒŸ
probes: divergence.Repeat
probes: divergence.RepeatExtended ğŸ’¤
```
En fait, il existe plusieurs variantes de probes pour un mÃªme jailbreak prompt.
Ces symboles ont la signification suivante :
- ğŸŒŸ : indique qu'on passe Ã  un nouveau module de jailbreak ici `divergence`.
- ğŸ’¤ : indique que la probe `divergence.RepeatExtended` est inactive par dÃ©faut, car son lancement serait long. C'est la version `divergence.Repeat` qui sera lancÃ©e en cas de scan automatique.

Pour lancer un scan automatique d'un module en particulier comme `divergence`, il suffit d'exÃ©cuter la commande suivante :
```bash

python -m garak --model_type huggingface --model_name gpt2 --probes divergence
```

Pour lancer une probe inactive comme `divergence.RepeatExtended`, il suffit d'exÃ©cuter la commande suivante :
```bash

python -m garak --model_type huggingface --model_name gpt2  --probes divergence.RepeatExtended
```

### Les generators

Les generators sont des abstractions (LLMs, APIs, fonction Python) rÃ©pondant un texte en fonction d'un input.
Les generators prennent les valeurs, dont :
- `huggingface` : pour les modÃ¨les hÃ©bergÃ©s sur HuggingFace.
- `openai` : pour les modÃ¨les OpenAI.
- `function` : pour les fonctions Python.

Par exemple, si on souhaite Ã©valuer un modÃ¨le `gpt2` de `Huggingface` lors d'un scan, on renseigne les options : `--model_type huggingface --model_name gpt2`.
Si c'est une API d'HuggingFace, on renseigne les options : `--model_name huggingface.InferenceAPI --model_type "mosaicml/mpt-7b-instruct"`.

Pour plus de dÃ©tails, vous pouvez consulter la documentation officielle de Garak : [Garak Documentation](https://docs.garak.ai/garak/garak-components/using-generators)

### Les detectors et les Harnesses

Comme, une probe va Ãªtre lancÃ©e plusieurs fois pour tester la robustesse du LLM et que l'on teste plusieurs probes, Garak utilise des detectors pour reconnaitre si la rÃ©ponse du LLM dÃ©faillante.
Ce sont des dÃ©tecteurs de mots-clÃ©s ou des classifiers jugeant si la rÃ©ponse d'un LLM est OK ou non.

Les Harnesses dÃ©signent quel dÃ©tector est utilisÃ© avec quelle probe. Les Harnesses prennent la valeur : `probewise` si on utilise les dÃ©tectors rÃ©commandÃ©s Ã  la probe ou `pxd` pour tester tous les dÃ©tecteurs.


## Mise en pratique de Garak

