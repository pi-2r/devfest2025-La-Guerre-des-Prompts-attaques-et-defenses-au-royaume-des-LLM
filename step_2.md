#  Pourquoi la S√©curit√© des LLM est-elle Cruciale ?

[<img src="img/step2.png" alt="gandalf" >](https://www.youtube.com/watch?v=whF2na8AIbw)
> "The year 3434 of the Second Age. Here follows the account of Isildur, High King of Gondor, and the finding of the ring 
> of power. It has come to me. The One Ring", Gandalf, LOTR - The Followship of the Ring

## üéØ Objectifs de cette √©tape

- Avoir une vue d'ensemble sur la nouvelle √®re technologique de l'IA g√©n√©rative.
- Comprendre l'importance de la s√©curit√© des LLM dans le contexte de l'IA g√©n√©rative.

## Sommaire

- [L'√©mergence de l'IA, une nouvelle √®re technologique](#l-emergence-de-l-ia-une-nouvelle-ere-technologique)


- [Le LLM, un cerveau connect√© √† vos programmes](#le-llm-un-cerveau-connecte-a-vos-programmes)
- [Les diff√©rents points de contr√¥le](#les-diff√©rents-points-de-contr√¥le)
  - [Interaction avec l'utilisateur](#interaction-avec-lutilisateur)
  - [Donn√©es d'entra√Ænement publique](#donn√©es-dentrainement-publique)
  - [Donn√©es d'entra√Ænement interne](#donn√©es-dentrainement-interne)
  - [Services internes](#services-internes)
  - [Acc√®s aux donn√©es publiques](#acc√®s-aux-donn√©es-publiques)

- [Le mod√®le LLM](#le-mod√®le-llm)
  - [Mod√®le par API](#mod√®le-par-api)
  - [Mod√®le h√©berg√©](#mod√®le-h√©berg√©)


- [√âtape suivante](#√©tape-suivante)
- [Ressources](#ressources)

## L'√©mergence de l'IA, une nouvelle √®re technologique

L‚Äôessor fulgurant de l‚Äôintelligence artificielle, port√© notamment par ChatGPT, a propuls√© cette technologie sur le 
devant de la sc√®ne. Son adoption massive ne se limite plus au grand public: les entreprises, s√©duites par l‚Äôefficacit√© 
des grands mod√®les de langage (LLM) dans les applications d‚ÄôIA g√©n√©rative, en font d√©sormais un levier incontournable 
de productivit√©.


<a href="https://www.visualcapitalist.com/charted-top-10-companies-leading-the-new-era-of-ai/" target="_blank">
  <img src="https://www.visualcapitalist.com/wp-content/uploads/2025/06/Companies-Leading-the-New-Era-of-AI_WEB-1.jpg" alt="image" width="450" style="transition:0.3s;">
</a>


Cependant, cette popularit√© s‚Äôaccompagne de nouveaux enjeux majeurs en mati√®re de s√©curit√©. Les LLM introduisent des 
risques sp√©cifiques, diff√©rents des menaces cyber classiques telles que les attaques DDoS, les injections SQL/XSS ou 
les ransomwares. Leur capacit√© √† interpr√©ter et g√©n√©rer du langage naturel via des prompts ouvre la voie √† des 
vuln√©rabilit√©s in√©dite : manipulation des requ√™tes, g√©n√©ration de contenus malveillants ou inappropri√©s, exfiltration 
d‚Äôinformations sensibles, ou encore actions non pr√©vues par les concepteurs du syst√®me. Voyons cela plus en d√©tails.


<!-- <a href="https://a16z.com/newsletter/october-2024-fintech-newsletter-fintech-isnt-dead-ai-is-driving-a-new-beginning/" target="_blank">
  <img src="img/era.jpg" alt="image" width="450" style="transition:0.3s;">
</a> -->


# Le LLM, un cerveau connect√© √† vos programmes

Les d√©veloppeurs, tout comme les entreprises qui les emploient, per√ßoivent fr√©quemment les grands mod√®les de langage (LLM)
comme des syst√®mes autonomes, capables d‚Äôexploits remarquables en mati√®re de compr√©hension et de g√©n√©ration de contenus. 
Pourtant, dans la r√©alit√© de l‚Äôing√©nierie logicielle, les LLM ne fonctionnent que rarement de mani√®re isol√©: 
ils s‚Äôint√®grent g√©n√©ralement au c≈ìur d‚Äôarchitectures d√©cisionnelles complexes, con√ßues pour accro√Ætre l‚Äôautonomie des applications.

Ces architectures reposent sur l‚Äôinterconnexion de multiples composants, chacun jouant un r√¥le sp√©cifique dans la cha√Æne
de traitement. Cette organisation modulaire est essentielle pour garantir la coh√©rence, la robustesse et la performance 
globale des solutions bas√©es sur l‚ÄôIA g√©n√©rative. Ainsi, le LLM agit comme un maillon central, mais il d√©pend √©troitement
de l‚Äôensemble du syst√®me pour d√©livrer des r√©sultats fiables et pertinents. Il est donc essentiel d‚Äôavoir une vision 
d‚Äôensemble de l‚Äôarchitecture qui entoure le LLM d√©ploy√©.

Le sch√©ma ci-dessous pr√©sente une version simplifi√©e de l‚Äôint√©gration d‚Äôun LLM dans un environnement d‚Äôentreprise.


 <img src="img/llm-inside.png" alt="llm-inside" width="450" style="transition:0.3s;">

En soi, la d√©marche reste relativement simple. Cependant, il est indispensable de mettre en place des points de contr√¥le
sur les connexions auxquelles le LLM a acc√®s. Ces contr√¥les peuvent prendre diff√©rentes formes, telles que l‚Äôauthentification, 
la validation des donn√©es ou encore la gestion des autorisations d‚Äôacc√®s.

Le sch√©ma ci-dessous propose une vue simplifi√©e des principaux points de contr√¥le √† consid√©rer.

 <img src="img/llm-inside-secure.png" alt="llm-inside" width="450" style="transition:0.3s;">

## Les diff√©rents points de contr√¥le

### Interaction avec l'utilisateur
Il est important de consid√©rer que les utilisateurs peuvent, intentionnellement ou non, introduire des erreurs. Il est 
donc essentiel de mettre en place des dispositifs visant √† prot√©ger le mod√®le LLM contre des entr√©es potentiellement 
contradictoires ou trompeuses, qu‚Äôelles proviennent des utilisateurs ou d‚Äôautres syst√®mes. Une vigilance particuli√®re 
doit √©galement √™tre accord√©e aux contenus toxiques, inexacts ou sensibles que le mod√®le pourrait g√©n√©rer et transmettre 
√† l‚Äôutilisateur.

### Donn√©es d'entra√Ænement publique
Les LLM sont g√©n√©ralement entra√Æn√©s √† partir d‚Äôimmenses ensembles de donn√©es issues d‚ÄôInternet. Il est donc essentiel de 
consid√©rer ces sources comme potentiellement peu fiables et de rester vigilant face aux risques de toxicit√©, de biais 
ou d‚Äôempoisonnement des donn√©es provenant d‚Äôinformations contradictoires. Exemple Grok avec son mod√®le issue de la 
plateforme X (anciennement Twitter) qui se base essentiellement sur les commentaires (Troll ?) des utilisateurs.

### Donn√©es d'entra√Ænement interne

Il est possible d‚Äôutiliser des donn√©es internes pour optimiser le mod√®le, ce qui peut sensiblement accro√Ætre sa pr√©cision. 
Toutefois, il est imp√©ratif de s‚Äôassurer que les informations sensibles, confidentielles ou √† caract√®re personnel ne 
soient ni int√©gr√©es ni expos√©es lors de ce processus.

### Services internes
Il est indispensable de ma√Ætriser la mani√®re dont le LLM interagit avec les services connect√©s de l‚Äôentreprise, tels 
que les bases de donn√©es ou les API, afin de pr√©venir toute interaction non autoris√©e ou fuite de donn√©es, comme des 
injections SQL ou des requ√™tes abusives sur les API.


### Acc√®s aux donn√©es publiques
L‚Äôextraction de donn√©es en temps r√©el depuis le Web, notamment par le biais de techniques de scraping, peut constituer 
un levier efficace pour enrichir les fonctionnalit√©s de votre application. Toutefois, il est essentiel de consid√©rer 
ces informations comme potentiellement peu fiables et de rester attentif √† des risques tels que l‚Äôinjection indirecte 
d‚Äôinvites. Cette vigilance doit √™tre renforc√©e si vous permettez aux utilisateurs de proposer des sites web √† explorer 
ou de t√©l√©verser des documents susceptibles d‚Äô√™tre compromis.

# Le mod√®le LLM

Le mod√®le de langage constitue le c≈ìur de toute application bas√©e sur un LLM. Il joue un r√¥le central en collectant et 
en interpr√©tant les informations afin de permettre l‚Äôex√©cution d‚Äôactions au sein d‚Äôun environnement informatique.

Selon la configuration de votre infrastructure et vos besoins sp√©cifiques, deux options s‚Äôoffrent √† vous pour permettre 
√† votre √©cosyst√®me d‚Äôinteragir avec le mod√®le :
- **Mod√®le par API** : Par le biais d‚Äôune API publique, h√©berg√©e par un prestataire externe (ex. OpenAI, Google, Amazon 
    Bedrock, etc.), qui permet d‚Äôacc√©der √† un mod√®le pr√©-entra√Æn√© et de l‚Äôutiliser pour g√©n√©rer des r√©ponses ou des actions.


- **Mod√®le h√©berg√©** : En d√©ployant un mod√®le h√©berg√© localement, au sein de vos propres installations (on-premises) ou 
    dans le cloud, ce qui vous permet de contr√¥ler enti√®rement le mod√®le et de l‚Äôadapter √† vos besoins sp√©cifiques.


## Mod√®le par API
todo

## Mod√®le h√©berg√©
todo


## √âtape suivante

- [√âtape 3](step_3.md)


## Ressources


| Information                                                                                         | Lien                                                                                                                                                                                                                                                                               |
|-----------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| How AI can move from hype to global solutions                                                       | [https://www.weforum.org/stories/2025/01/ai-transformation-industries-responsible-innovation/](https://www.weforum.org/stories/2025/01/ai-transformation-industries-responsible-innovation/)                                                                                       |
| ChatGPT s√©duit les pros : 32 % des entreprises US utilisent OpenAI, loin devant Google et Anthropic | [https://siecledigital.fr/2025/05/12/chatgpt-seduit-les-pros-32-des-entreprises-us-utilisent-openai-loin-devant-google-et-anthropic/](https://siecledigital.fr/2025/05/12/chatgpt-seduit-les-pros-32-des-entreprises-us-utilisent-openai-loin-devant-google-et-anthropic/)         |
| Large language models : les nouveaux enjeux √† venir dans la cybers√©curit√©                           | [https://www.journaldunet.com/intelligence-artificielle/1542135-large-language-models-les-nouveaux-enjeux-a-venir-dans-la-cybersecurite/](https://www.journaldunet.com/intelligence-artificielle/1542135-large-language-models-les-nouveaux-enjeux-a-venir-dans-la-cybersecurite/) |
| Vuln√©rabilit√©s LLM et s√©curit√© des IA g√©n√©ratives                                                   | [https://www.vaadata.com/blog/fr/vulnerabilites-llm-et-securite-des-ia-generatives/](https://www.vaadata.com/blog/fr/vulnerabilites-llm-et-securite-des-ia-generatives/)                                                                                                           |
| L'IA en cybers√©curit√© : comprendre les risques                                                      | [https://www.malwarebytes.com/fr/cybersecurity/basics/risks-of-ai-in-cyber-security](https://www.malwarebytes.com/fr/cybersecurity/basics/risks-of-ai-in-cyber-security)                                                                                                           | 
 

