# Test de Robustesse ?

[<img src="img/step8.png" alt="hobbiton" width="800">](https://www.youtube.com/watch?v=NFBXilomkPk)
> "Oh... you would not part an old man from his walking stick?", Gandalf, LOTR - The Two Towers

## üéØ Objectifs de cette √©tape

- Todo


## Sommaire

- [Introduction](#introduction)
- [Objectif principal](#objectif-principal)

- [Contexte des Attaques cibl√©es](#contexte-des-attaques-cibl√©es)

- [Garak vs PyRIT](#garak-vs-pyrit)
- [√âtape suivante](#√©tape-suivante)
- [Ressources](#ressources)


## Introduction

Les **tests de robustesse**, √©galement appel√©s **tests adversariaux**, repr√©sentent un √©l√©ment cl√© de la s√©curit√© des syst√®mes 
d‚Äôintelligence artificielle (IA) et d‚Äôapprentissage automatique (ML). Ils visent avant tout **√† mesurer la capacit√© d‚Äôun 
mod√®le √† rester fiable et performant** lorsqu‚Äôil est confront√© √† des donn√©es volontairement con√ßues pour l‚Äôinduire en 
erreur ou le manipuler.


## Objectif principal

L'objectif principal des tests de robustesse ont pour but d‚Äô√©valuer la capacit√© d‚Äôun mod√®le √† pr√©server ses 
performances et son int√©grit√© face √† des entr√©es malveillantes ou alt√©r√©es de mani√®re subtile. Ils cherchent √† s‚Äôassurer
que le mod√®le conserve un comportement conforme aux attentes et ne g√©n√®re pas de r√©sultats erron√©s ou potentiellement
dangereux lorsqu‚Äôil est soumis √† des attaques.

## Contexte des Attaques cibl√©es

Ces tests sont cruciaux pour se d√©fendre contre deux cat√©gories principales d'attaques adversariales:
- **Attaques par Empoisonnement des Donn√©es (Poisoning Attacks)**
- **Attaques par √âvasion (Evasion Attacks)**
- 

## Garak vs PyRIT
Deux outils open source populaires pour effectuer des tests de robustesse sur les mod√®les d'IA g√©n√©rative 
sont **Garak** et **PyRIT**.

**Garak** repose sur une biblioth√®que d‚Äôattaques d√©j√† connues qu‚Äôil lance pour tester, tandis que **PyRIT** permet de 
personnaliser, cha√Æner et automatiser des sc√©narios d‚Äôattaque complexes selon la politique de s√©curit√© souhait√©e.



## √âtape suivante
- [√âtape 9](step_9.md)

## Ressources


| Information                                                                               | Lien                                                                                                                                                                                                                                 |
|-------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Promptfoo vs Deepteam vs PyRIT vs Garak: The Ultimate Red Teaming Showdown for LLMs       | [https://dev.to/ayush7614/promptfoo-vs-deepteam-vs-pyrit-vs-garak-the-ultimate-red-teaming-showdown-for-llms-48if](https://dev.to/ayush7614/promptfoo-vs-deepteam-vs-pyrit-vs-garak-the-ultimate-red-teaming-showdown-for-llms-48if) |
| AI Security in Action: Applying NVIDIA‚Äôs Garak to LLMs on Databricks                      | [https://www.databricks.com/blog/ai-security-action-applying-nvidias-garak-llms-databricks](https://www.databricks.com/blog/ai-security-action-applying-nvidias-garak-llms-databricks)                                               |
| Garak: A Framework for Security Probing Large Language Models                             | [https://arxiv.org/abs/2407.13499](https://arxiv.org/abs/2407.13499)                                                                                                                                                                 |
| PyRIT: Framework for Security Risk Identification and Red Teaming in Generative AI System | [https://arxiv.org/abs/2407.13498](https://arxiv.org/abs/2407.13498)                                                                                                                                                                 |
