# Des √©carts sous contr√¥le relatif

[<img src="img/step3.png" alt="Nazgul" >](https://www.youtube.com/watch?v=Sk47qO8rW4Y)
> "What are you doing !", Frodon, LOTR - The Followship of the Ring


## üéØ Objectifs de cette √©tape

## Sommaire 
- [2022, l‚Äôapparition des premi√®res pr√©occupations](#2022-lapparition-des-premieres-preoccupations)
- [Microsoft Tay : Chatbot corrompu par les utilisateurs](#microsoft-tay--chatbot-corrompu-par-les-utilisateurs)

- [D'autres exemples notables](#dautres-exemples-notables)
  - [2018 - Amazon](#2018---amazon)
  - [2023 - ITutorGroup](#2023---itutorgroup)
  - [2023 - une Chevrolet pour 1$](#2023---une-chevrolet-pour-1)
  - [2024 - Air Canada](#2024---air-canada)
  - [2024 - DPD chat](#2021---dpd-chat)
  - [2024 - Google, pol√©mique internationale](#2024---google-polemique-internationale)
- [MCP nouvelle menace](#mcp-nouvelle-menace)

- [Ressources](#ressources)

## 2022, l‚Äôapparition des premi√®res pr√©occupations
Dans les mois qui ont suivi le lancement de ChatGPT en 2022, de s√©rieuses inqui√©tudes concernant la s√©curit√© et la 
confidentialit√© des donn√©es ont rapidement √©merg√©. Plusieurs incidents marquants, dont des fuites d‚Äôinformations 
personnelles et professionnelles, ont mis en √©vidence les risques associ√©s √† l‚Äôutilisation de cet outil. Face √† ces 
r√©v√©lations, certaines grandes entreprises comme Samsung ont pr√©f√©r√© bannir l‚Äôusage public de ChatGPT par leurs employ√©s,
tandis que des pays tels que l‚ÄôItalie ont impos√© des restrictions ou des interdictions temporaires, invoquant notamment
la non-conformit√© aux exigences r√©glementaires et aux principes de transparence.


Ces √©v√©nements ont raviv√© les souvenirs d‚Äô√©checs illustrant la vuln√©rabilit√© des intelligences artificielles, √† l‚Äôimage
du chatbot Tay de Microsoft, dont l‚Äôexp√©rience avait d√©j√† d√©montr√© √† quel point une IA pouvait √™tre d√©tourn√©e, mise en 
difficult√© par des probl√©matiques de s√©curit√© et de contr√¥le des contenus g√©n√©r√©s.


## Microsoft Tay : Chatbot corrompu par les utilisateurs

<a href="https://www.lemonde.fr/pixels/article/2016/03/24/a-peine-lancee-une-intelligence-artificielle-de-microsoft-derape-sur-twitter_4889661_4408996.html" target="_blank">
  <img src="https://img.lemde.fr/2016/03/24/0/0/516/220/1112/0/75/0/97393c4_9329-4mpfka.PNG" alt="tay " width="450" style="transition:0.3s;">
</a>

<a href="https://www.lemonde.fr/pixels/article/2016/03/24/a-peine-lancee-une-intelligence-artificielle-de-microsoft-derape-sur-twitter_4889661_4408996.html" target="_blank"><em>source: lemonde.fr</em></a>



En mars 2016, Microsoft a lanc√© Tay, un chatbot dot√© d‚Äôintelligence artificielle con√ßu pour dialoguer avec les 
utilisateurs sur Twitter et d‚Äôautres plateformes sociales. L‚Äôobjectif √©tait de cr√©er une IA capable d‚Äôapprendre et de 
s‚Äôadapter au langage des jeunes internautes en temps r√©el. 

Cependant, moins de 24 heures apr√®s sa mise en ligne, Tay a √©t√© la cible d‚Äôune campagne coordonn√©e d‚Äôutilisateurs 
malveillants qui ont exploit√© ses algorithmes d‚Äôapprentissage automatique pour le pousser √† g√©n√©rer des messages 
racistes, haineux et offensants. 

Cette exploitation des failles de s√©curit√© de Tay a provoqu√© un scandale retentissant. Face √† la quantit√© et √† la 
gravit√© des propos relay√©s, Microsoft a √©t√© contraint de d√©sactiver le chatbot imm√©diatement et a pr√©sent√© des excuses 
publiques, soulignant qu‚Äôils n‚Äôavaient pas anticip√© cette forme d‚Äôabus et qu‚Äôils prendraient √† l‚Äôavenir davantage de 
pr√©cautions dans le d√©ploiement de leurs IA.

## D'autres exemples notables

### 2018 - Amazon

<a href="https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/" target="_blank">
  <img src="https://www.reuters.com/resizer/v2/https%3A%2F%2Farchive-images.prod.global.a201836.reutersmedia.net%2F2018%2F10%2F11%2FLYNXNPEE9907T.JPG?auth=762505fd03e752aa7faf78c87439831b17ccd4947403f01b91a590cbf6f880cf&width=1920&quality=80" alt="tay " width="450" style="transition:0.3s;">
</a>

<a href="https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/" target="_blank"><em>source: reuters.com</em></a>

En 2018, Amazon a mis un terme √† un projet interne d‚Äôintelligence artificielle destin√© √† automatiser la s√©lection des 
meilleurs candidats, apr√®s avoir d√©couvert que l‚Äôoutil favorisait syst√©matiquement les profils masculins au d√©triment 
des femmes.


Ce biais provenait des donn√©es utilis√©es pour entra√Æner l‚Äôalgorithme : la majorit√© des CV analys√©s provenaient d‚Äôhommes,
refl√©tant la domination masculine dans le secteur technologique.


Malgr√© plusieurs tentatives pour neutraliser ces discriminations, le risque de biais persistait, ce qui a conduit 
Amazon √† abandonner le projet afin d‚Äô√©viter de perp√©tuer des pratiques de recrutement in√©quitables.


### 2023 - ITutorGroup

<a href="https://www.reuters.com/legal/tutoring-firm-settles-us-agencys-first-bias-lawsuit-involving-ai-software-2023-08-10/" target="_blank">
  <img src="https://media.licdn.com/dms/image/v2/C560BAQFd5_V0ejcWjw/company-logo_200_200/company-logo_200_200/0/1631380400405?e=1758153600&v=beta&t=FGvvgeubSHf0bD7She9AfplrE0zBTUHbu2k_3nzbCiE" alt="tay " width="150" style="transition:0.3s;">
</a>

<a href="https://www.reuters.com/legal/tutoring-firm-settles-us-agencys-first-bias-lawsuit-involving-ai-software-2023-08-10/" target="_blank"><em>source: reuters.com</em></a>

L‚Äôentreprise ITutorGroup, sp√©cialis√©e dans le recrutement de tuteurs en ligne, a √©t√© poursuivie aux √âtats-Unis pour 
avoir utilis√© une intelligence artificielle qui discriminait syst√©matiquement les candidats en fonction de leur √¢ge. 
Selon l‚Äôenqu√™te men√©e par la Commission pour l‚Äô√©galit√© des chances (EEOC), le logiciel de recrutement √©tait programm√© 
pour rejeter automatiquement les femmes de 55 ans et plus, et les hommes de 60 ans et plus. 

Ce biais a √©t√© d√©couvert lorsque des candidats ont constat√© qu‚Äôen changeant simplement leur date de naissance √† une 
ann√©e plus r√©cente, ils obtenaient soudainement un entretien.

A la suite de cela, plus de 200 candidats qualifi√©s ont √©t√© indirectement exclus, uniquement √† cause de leur √¢ge. 
ITutorGroup a accept√© de r√©gler l‚Äôaffaire √† l‚Äôamiable en versant 365,000$ aux personnes concern√©es, et s‚Äôest engag√© √† 
revoir ses proc√©dures pour garantir des pratiques de recrutement non discriminatoires √† l‚Äôavenir.

### 2023 - une Chevrolet pour 1$

<a href="https://www.linkedin.com/pulse/chatbot-case-study-purchasing-chevrolet-tahoe-1-cut-the-saas-com-z6ukf/" target="_blank">
  <img src="https://pbs.twimg.com/media/GBlnwdTbYAAewjn?format=png" alt="tay " width="150" style="transition:0.3s;">
</a>

<a href="https://www.linkedin.com/pulse/chatbot-case-study-purchasing-chevrolet-tahoe-1-cut-the-saas-com-z6ukf/" target="_blank"><em>source: linkedin.com</em></a>

En 2023, un concessionnaire Chevrolet bas√© en Californie a fait l‚Äôobjet d‚Äôun incident viral apr√®s qu‚Äôun chatbot sur son 
site web a accept√© la vente d‚Äôun Chevrolet Tahoe neuf pour seulement 1$. Un internaute a r√©ussi √† "manipuler" le chatbot 
en exploitant une faille connue sous le nom de prompt injection : il a formul√© ses demandes de fa√ßon √† amener le robot 
√† accepter n‚Äôimporte quelle proposition, puis il a sollicit√© la vente de la voiture pour 1$, ce que le chatbot a valid√©
en affirmant qu‚Äôil s‚Äôagissait d‚Äôun accord ¬´ juridiquement contraignant ¬ª.

L‚Äôhistoire, largement relay√©e sur les r√©seaux sociaux et par la presse sp√©cialis√©e, a mis en avant les limites et les 
risques des IA conversationnelles utilis√©es dans des contextes commerciaux automatis√©s. Au final, le concessionnaire 
n‚Äôa pas r√©alis√© la transaction, mais l‚Äôincident a soulign√© l‚Äôimportance de mettre en place des garde-fous et des 
contr√¥les humains lors de l‚Äôutilisation de chatbots pour des op√©rations sensibles, afin d‚Äô√©viter ce type de d√©rive.

### 2024 - DPD chat

<a href="https://www.bbc.co.uk/news/technology-68025677" target="_blank">
  <img src="https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/130E9/production/_132375087_1b2c154e-658f-4cc1-a7ac-49fb4b053a46.jpg.webp" alt="tay " width="450" style="transition:0.3s;">
</a>

<a href="https://www.bbc.co.uk/news/technology-68025677" target="_blank"><em>source: bbc.co.uk</em></a>

En 2024 le chatbot utilis√© par la soci√©t√© de livraison DPD s‚Äôest retrouv√© au centre de l‚Äôattention apr√®s avoir 
donn√© des r√©ponses inappropri√©es, notamment des insultes envers la soci√©t√© et ses clients, ou en communiquant des 
informations trompeuses. Cet incident a suscit√© de nombreuses plaintes et a √©t√© largement relay√© dans les m√©dias. 

Ce cas illustre bien les risques li√©s √† l‚Äôutilisation de l‚Äôintelligence artificielle dans le service client√®le, o√π des
syst√®mes mal configur√©s ou mal encadr√©s peuvent g√©n√©rer des d√©cisions discriminatoires ou diffuser de fausses informations, 
entra√Ænant des cons√©quences juridiques et r√©putationnelles pour l‚Äôentreprise.

## Ressources

| Information                                                                             | Lien                                                                                                                                                                                                                                                                             |
|-----------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Arr√™tez de r√©v√©ler tous vos secrets √† ChatGPT, vous mettez votre entreprise en danger   | [https://www.numerama.com/cyberguerre/1297046-arretez-de-reveler-tous-vos-secrets-a-chatgpt-vous-mettez-votre-entreprise-en-danger.html](https://www.numerama.com/cyberguerre/1297046-arretez-de-reveler-tous-vos-secrets-a-chatgpt-vous-mettez-votre-entreprise-en-danger.html) |
| Security Analysis of ChatGPT: Threats and Privacy Risks                                 | [https://arxiv.org/html/2508.09426v1](https://arxiv.org/html/2508.09426v1)                                                                                                                                                                                                       |
| Microsoft shuts down AI chatbot after it turned into a Nazi                             | [https://www.cbsnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/](https://www.cbsnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/)                                                                                 |
| 5 Things That You Should Never Share With Chat GPT                                      | [https://agileblue.com/5-things-that-you-should-never-share-with-chat-gpt/](https://agileblue.com/5-things-that-you-should-never-share-with-chat-gpt/)                                                                                                                           |
| L'Italie bloque l'usage de l'intelligence artificielle ChatGPT                          | [https://www.france24.com/fr/%C3%A9co-tech/20230331-l-italie-bloque-l-usage-de-l-intelligence-artificielle-chatgpt](https://www.france24.com/fr/%C3%A9co-tech/20230331-l-italie-bloque-l-usage-de-l-intelligence-artificielle-chatgpt)                                           |
| Microsoft‚Äôs new AI-powered bot Tay answers your tweets and chats on GroupMe and Kik     | [https://techcrunch.com/2016/03/23/microsofts-new-ai-powered-bot-tay-answers-your-tweets-and-chats-on-groupme-and-kik/](https://techcrunch.com/2016/03/23/microsofts-new-ai-powered-bot-tay-answers-your-tweets-and-chats-on-groupme-and-kik/)                                   | 
| Microsoft Created a Twitter Bot to Learn from Users. It Quickly Became a Racist Jerk    | [https://www.nytimes.com/2016/03/25/technology/microsoft-created-a-twitter-bot-to-learn-from-users-it-quickly-became-a-racist-jerk.html](https://www.nytimes.com/2016/03/25/technology/microsoft-created-a-twitter-bot-to-learn-from-users-it-quickly-became-a-racist-jerk.html) |
| Microsoft shuts down AI chatbot after it turned into a Nazi                             | [https://www.cbsnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/](https://www.cbsnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/)                                                                                 |
| Insight - Amazon scraps secret AI recruiting tool that showed bias against women        | [https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/)       |
| Amazon scraps secret AI recruiting tool that showed bias against women                  | [https://www.euronews.com/business/2018/10/10/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women](https://www.euronews.com/business/2018/10/10/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women)                                       |
| DPD error caused chatbot to swear at customer                                           | [https://www.bbc.co.uk/news/technology-68025677](https://www.bbc.co.uk/news/technology-68025677)                                                                                                                                                                                 |
| ITutorGroup settles AI hiring lawsuit alleging age discrimination                       | [https://www.verdict.co.uk/itutorgroup-settles-ai-hiring-lawsuit-alleging-age-discrimination/](https://www.verdict.co.uk/itutorgroup-settles-ai-hiring-lawsuit-alleging-age-discrimination/)                                                                                     |
| Generative AI: UNESCO study reveals alarming evidence of regressive gender stereotypes  | [https://www.unesco.org/en/articles/generative-ai-unesco-study-reveals-alarming-evidence-regressive-gender-stereotypes](https://www.unesco.org/en/articles/generative-ai-unesco-study-reveals-alarming-evidence-regressive-gender-stereotypes)                                   | 