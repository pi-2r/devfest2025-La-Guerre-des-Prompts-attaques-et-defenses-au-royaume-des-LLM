# Des ressources pour aller plus loin sur le sujet de sécurité des LLMs et des chatbots

<img src="img/Cthulhu.png"  alt="resources">

> "Nous vivons sur une île paisible d'ignorance au milieu des mers noires de l'infini, et il n'était pas prévu que nous voyagions loin.", H.P. Lovecraft


- Sommaire :
    - [Lecture web](#lecture-web)
    - [Livres](#livres)
    - [Vidéos et conférences](#vidéos-et-conférences)
    - [Lecture académique](#lecture-académique)
    - [Cours et certifications](#cours-et-certifications)

## Lecture web

| Information                                                                                                                                  | Lien                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
|----------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ChatGPT Jailbreak Prompts: How to Unchain ChatGPT                                                                                            | [https://docs.kanaries.net/articles/chatgpt-jailbreak-prompt](https://docs.kanaries.net/articles/chatgpt-jailbreak-prompt)                                                                                                                                                                                                                                                                                                                                                                                         |
| ChatGPT jailbreak                                                                                                                            | [https://www.lebigdata.fr/chatgpt-dan](https://www.lebigdata.fr/chatgpt-dan)                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| How to Jailbreak ChatGPT 4 in 2024 (Prompt + Examples)                                                                                       | [https://weam.ai/blog/guide/jailbreak-chatgpt/](https://weam.ai/blog/guide/jailbreak-chatgpt/)                                                                                                                                                                                                                                                                                                                                                                                                                     |
| The Developer's Playbook for Large Language Model Security: Building Secure AI Applications                                                  | [https://www.oreilly.com/library/view/the-developers-playbook/9781098162191/](https://www.oreilly.com/library/view/the-developers-playbook/9781098162191/)                                                                                                                                                                                                                                                                                                                                                         |
| Playing Language Game with LLMs Leads to Jailbreaking                                                                                        | [https://arxiv.org/pdf/2411.12762](https://arxiv.org/pdf/2411.12762)                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking | [https://arxiv.org/pdf/2409.08045](https://arxiv.org/pdf/2409.08045)                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| La méthode "Crescendo" permet de jailbreaker l'IA de type LLM, en utilisant des invites en apparence inoffensives                            | [https://intelligence-artificielle.developpez.com/actu/356562/La-methode-Crescendo-permet-de-jailbreaker-l-IA-de-type-LLM-en-utilisant-des-invites-en-apparence-inoffensives-afin-de-produire-des-resultats-qui-seraient-normalement-filtres-et-refuses/](https://intelligence-artificielle.developpez.com/actu/356562/La-methode-Crescendo-permet-de-jailbreaker-l-IA-de-type-LLM-en-utilisant-des-invites-en-apparence-inoffensives-afin-de-produire-des-resultats-qui-seraient-normalement-filtres-et-refuses/) |
| Jailbreaking LLMs: A Comprehensive Guide (With Examples)                                                                                     | [https://www.promptfoo.dev/blog/how-to-jailbreak-llms/](https://www.promptfoo.dev/blog/how-to-jailbreak-llms/)                                                                                                                                                                                                                                                                                                                                                                                                     |
| Récentes Avancées dans la Recherche sur le Jailbreak des LLM                                                                                 | [hhttps://docs.kanaries.net/fr/topics/ChatGPT/llm-jailbreak-papers](https://docs.kanaries.net/fr/topics/ChatGPT/llm-jailbreak-papers)                                                                                                                                                                                                                                                                                                                                                                              |
| Defining LLM Red Teaming                                                                                                                     | [https://developer.nvidia.com/blog/defining-llm-red-teaming/](https://developer.nvidia.com/blog/defining-llm-red-teaming/)                                                                                                                                                                                                                                                                                                                                                                                         |
| Red Teaming LLMs: The Ultimate Step-by-Step LLM Red Teaming Guide                                                                            | [https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide](https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide)                                                                                                                                                                                                                                                                                                                                                                 |
| Planification de la Red Team pour les modèles de langage volumineux (LLMs) et leurs applications                                             | [https://learn.microsoft.com/fr-fr/azure/ai-services/openai/concepts/red-teaming](https://learn.microsoft.com/fr-fr/azure/ai-services/openai/concepts/red-teaming)                                                                                                                                                                                                                                                                                                                                                 |
| Red-Teaming Large Language Models                                                                                                            | [https://huggingface.co/blog/red-teaming](https://huggingface.co/blog/red-teaming)                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| Multi-Chain Prompt Injection Attacks                                                                                                         | [https://labs.withsecure.com/publications/multi-chain-prompt-injection-attacks](https://labs.withsecure.com/publications/multi-chain-prompt-injection-attacks)                                                                                                                                                                                                                                                                                                                                                     |
| The State of Attacks on GenAI                                                                                                                | [https://45700826.fs1.hubspotusercontent-na1.net/hubfs/45700826/The%20State%20of%20Attacks%20on%20GenAI%20-%20Pillar%20Security.pdf](https://45700826.fs1.hubspotusercontent-na1.net/hubfs/45700826/The%20State%20of%20Attacks%20on%20GenAI%20-%20Pillar%20Security.pdf)                                                                                                                                                                                                                                           |
| Embrace The Red                                                                                                                              | [https://embracethered.com](https://embracethered.com)                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| LLM Security                                                                                                                                 | [https://llmsecurity.net/](https://llmsecurity.net/)                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Offensive ML Playbook                                                                                                                        | [https://wiki.offsecml.com/](https://wiki.offsecml.com/)                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| Intelligence Artificielle : les travaux de l’ANSSI                                                                                           | [https://cyber.gouv.fr/intelligence-artificielle-les-travaux-de-lanssi](https://cyber.gouv.fr/intelligence-artificielle-les-travaux-de-lanssi)                                                                                                                                                                                                                                                                                                                                                                     | 

## Livres

| Titre                                                                                                             | Auteur(s)                           | Partie concernée  | Lien                                                                                                           |
|-------------------------------------------------------------------------------------------------------------------|-------------------------------------|-------------------|----------------------------------------------------------------------------------------------------------------|
| Generative AI for Software Development                                                                            | Sergio Pereira                      | Tout le livre     | https://learning.oreilly.com/library/view/generative-ai-for/9781098162269                                      |
| The Developer's Playbook for Large Language Model Security: Building Secure AI Applications                       | Steve Wilson                        | Tout le livre     | https://www.oreilly.com/library/view/the-developers-playbook/9781098162191/                                    |
| AI Engineering: Building Applications with Foundation Models                                                      | Chip Huyen                          | Tout le livre     | https://www.oreilly.com/library/view/ai-engineering/9781098166298/                                             |
| Hands-On Large Language Models: Language Understanding and Generation                                             | Jay Alammar, Maarten Grootendorst   | Tout le livre     | https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/                                    |
| Adversarial ai attacks, mitigations, and defense strategies                                                       | John Sotiropoulos                   | Tout le livre     | https://www.packtpub.com/en-ch/product/adversarial-ai-attacks-mitigations-and-defense-strategies-9781835087985 |
| AI-Driven Cybersecurity and Threat Intelligence: Cyber Automation, Intelligent Decision-Making and Explainability | Iqbal H. Sarker                     | Tout le livre     | https://link.springer.com/book/10.1007/978-3-031-54497-2                                                       |
| Red Teaming AI: Attacking & Defending Intelligent Systems                                                         | Philip A. Dursey                    | Tout le livre     | https://www.amazon.com.au/Red-Teaming-Attacking-Defending-Intelligent-ebook/dp/B0F88SGMXG                      |


## Vidéos et conférences

| Titre                                                                                                                                              | Intervenant(s)                             | Événement                               | Lien                                                                           |
|----------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------|
| Hijacking AI Memory: Inside Johann Rehberger's Chat GPT Security Breakthrough                                                                      | Strike Graph                               | Vidéo Youtube                           | https://www.youtube.com/watch?v=_wFNroN9g_0                                    |  


## Lecture académique

| Titre                                                                                  | Type                         | Auteur(s)        | Lien                                                                                                                  |
|----------------------------------------------------------------------------------------|------------------------------|------------------|-----------------------------------------------------------------------------------------------------------------------|
| Attention Is All You Need                                                              | Article scientifique (arXiv) | Vaswani et al.   | https://arxiv.org/abs/1706.03762                                                                                      |
| ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs                      | Article scientifique (arXiv) | -                | https://arxiv.org/abs/2402.11753                                                                                      |
| Trust No AI: Prompt Injection Along The CIA Security Triad                             | Article scientifique (arXiv) | Johann Rehberger | https://arxiv.org/abs/2412.06090                                                                                      |
| owasp llm TOP 10                                                                       | Livre blanc                  | OWASP            | https://owasp.org/www-project-top-10-for-large-language-model-applications/                                           |
| GenAI Incident Response Guide                                                          | Livre blanc                  | OWASP            | https://genai.owasp.org/resource/genai-incident-response-guide-1-0/                                                   |
| Generative AI: UNESCO study reveals alarming evidence of regressive gender stereotypes | Étude                        | UNESCO           | https://www.unesco.org/en/articles/generative-ai-unesco-study-reveals-alarming-evidence-regressive-gender-stereotypes |
| Papers on ArXiv                                                                        | Paper stack                  | Dreadnode        | http://dreadnode.notion.site/?v=74ab79ed1452441dab8a1fa02099fedb                                                      |


## Cours et certifications

| Titre                                                                                 | Plateforme                     | Lien                                                                                                                              |
|---------------------------------------------------------------------------------------|--------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| Artificial Intelligence for Beginners - A Curriculum                                  | GitHub                         | https://microsoft.github.io/AI-For-Beginners/                                                                                     |
| Beginner: Introduction to Generative AI Learning Path                                 | Google Cloud Skills Boost      | https://www.cloudskillsboost.google/paths/118                                                                                     |
| HarvardX: CS50's Introduction to Artificial Intelligence with Python                  | edX                            | https://www.edx.org/course/cs50s-introduction-to-artificial-intelligence-with-python                                              |
| Prompt Engineering for ChatGPT                                                        | Coursera                       | https://www.coursera.org/learn/prompt-engineering                                                                                 |
| Big Data, Artificial Intelligence, and Ethics                                         | Coursera                       | https://www.coursera.org/learn/big-data-ai-ethics                                                                                 |
| Generative AI with Large Language Models                                              | Coursera                       | https://www.coursera.org/learn/generative-ai-with-llms                                                                            |
| Présentation de la sécurité dans le monde de l'IA                                     | Google                         | https://www.cloudskillsboost.google/paths/1283/course_templates/1147?locale=fr                                                    |
| Red Teaming LLM Applications                                                          | DeepLearning.AI                | https://learn.deeplearning.ai/courses/red-teaming-llm-applications                                                                |
| Exploring Adversarial Machine Learning                                                | NVIDIA                         | https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-DS-03+V1                                                 |
| Microsoft AI Red Team                                                                 | Microsoft Learn                | https://learn.microsoft.com/en-us/security/ai-red-team/                                                                           |
| LLM Red Teaming                                                                       | OffSec                         | https://www.offsec.com/learning/paths/llm-red-teaming                                                                             |
| IBM: Spécialisation L'IA générative d'IBM pour les professionnels de la cybersécurité | Coursera                       | https://www.coursera.org/specializations/generative-ai-for-cybersecurity-professionals                                            |
| Certified AI/ML Pentester (C-AI/MLPen)                                                | Pentesting Exams               | https://pentestingexams.com/product/certified-ai-ml-pentester/                                                                    |
| Portswigger Web Security Academy                                                      | Portswigger                    | https://portswigger.net/web-security/llm-attacks                                                                                  |
| Gandalf                                                                               | Lakera                         | https://gandalf.lakera.ai/                                                                                                        |
| IBM                                                                                   | IBM                            | https://www.ibm.com/topics/prompt-injection                                                                                       |
| Learn Prompting                                                                       | Learn Prompting                | https://learnprompting.org/docs/prompt_hacking/injection                                                                          |
| LLM Security                                                                          | llmsecurity.net                | https://llmsecurity.net/                                                                                                          |
| OWASP                                                                                 | OWASP                          | https://genai.owasp.org/                                                                                                          |
| AI Village                                                                            | AI Village                     | https://aivillage.org/large%20language%20models/threat-modeling-llm/                                                              |
| Promptingguide                                                                        | PromptingGuide                 | https://www.promptingguide.ai/risks/adversarial                                                                                   |
| Promptingguide RAG                                                                    | PromptingGuide                 | https://www.promptingguide.ai/research/rag                                                                                        |
| Cobalt                                                                                | Cobalt                         | https://www.cobalt.io/blog/prompt-injection-attacks                                                                               |
| Bugcrowd                                                                              | Bugcrowd                       | https://www.bugcrowd.com/blog/ai-vulnerability-deep-dive-prompt-injection/                                                        |
| Unite AI                                                                              | Unite AI                       | https://www.unite.ai/prompt-hacking-and-misuse-of-llm/?trk=article-ssr-frontend-pulse_little-text-block                           |
| Simonwillison                                                                         | Simon Willison                 | https://simonwillison.net/2023/May/2/prompt-injection-explained/                                                                  |
| Vickieli                                                                              | Vickieli                       | https://vickieli.medium.com/hacking-llms-with-prompt-injections-6a5ebffb182b                                                      |
| NCC Group                                                                             | NCC Group                      | https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/                                                      |
| WithSecureLabs                                                                        | WithSecureLabs                 | https://github.com/WithSecureLabs/damn-vulnerable-llm-agent                                                                       |
| ScottLogic                                                                            | ScottLogic                     | https://github.com/ScottLogic/prompt-injection                                                                                    |
| Greshake                                                                              | Greshake                       | https://github.com/greshake/llm-security                                                                                          |
| Hannibal046                                                                           | Hannibal046                    | https://github.com/Hannibal046/Awesome-LLM                                                                                        |
| Ottosulin                                                                             | Ottosulin                      | https://github.com/ottosulin/awesome-ai-security                                                                                  |
| Mik0w                                                                                 | Mik0w                          | https://github.com/mik0w/pallms                                                                                                   |
| ATLAS Matrix                                                                          | MITRE ATLAS                    | https://atlas.mitre.org/matrices/ATLAS/                                                                                           |
| Vulnerable LLM Applications                                                           | OWASP/ScottLogic               | https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Vulnerable-LLM-Applications                |
| Awesome-llm-security                                                                  | corca-ai                       | https://github.com/corca-ai/awesome-llm-security                                                                                  |
| Prompt Airlines                                                                       | Prompt Airlines                | https://promptairlines.com/                                                                                                       |
| Crucible                                                                              | Crucible                       | https://crucible.dreadnode.io/                                                                                                    |
| Immersive Labs                                                                        | Immersive Labs                 | https://prompting.ai.immersivelabs.com/                                                                                           |
| Bugcrowd Ultimate Guide AI Security                                                   | Bugcrowd                       | https://www.bugcrowd.com/wp-content/uploads/2024/04/Ultimate-Guide-AI-Security.pdf                                                |
| AI Red Teaming                                                                        | Microsoft Azure                | https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming                                                   |
| The Ultimate Guide to Managing Ethical and Security Risks in AI                       | HackerOne                      | https://www.hackerone.com/resources/e-book/the-ultimate-guide-to-managing-ethical-and-security-risks-in-ai                        |
| NVIDIA AI Red Team: An Introduction                                                   | NVIDIA                         | https://developer.nvidia.com/blog/nvidia-ai-red-team-an-introduction/                                                             |
| Lakera - Real World LLM Exploits                                                      | Lakera                         | https://lakera-marketing-public.s3.eu-west-1.amazonaws.com/Lakera%2BAI%2B-%2BReal%2BWorld%2BLLM%2BExploits%2B(Jan%2B2024)-min.pdf |
| SpyLogic Prompt Injection Attack Playground                                           | ScottLogic/Security Playground | https://github.com/ScottLogic/prompt-injection                                                                                    |
| Offensive ML Playbook                                                                 | OffSec ML                      | https://wiki.offsecml.com/Welcome+to+the+Offensive+ML+Playbook                                                                    |
| Snyk OWASP top 10 LLM                                                                 | Snyk                           | https://go.snyk.io/rs/677-THP-415/images/owasp-top-10-llm.pdf                                                                     |
| Prompt Injection Games from Secdim                                                    | Secdim                         | https://play.secdim.com/game/ai                                                                                                   |
| Large Language Model (LLM) Pentesting                                                 | SystemWeakness                 | https://systemweakness.com/large-language-model-llm-pen-testing-part-i-2ef96acb6763                                               |
| LLM Pentest: Leveraging Agent Integration for RCE                                     | BlazeInfosec                   | https://www.blazeinfosec.com/post/llm-pentest-agent-hacking/                                                                      |