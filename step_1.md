

## 2022 le lancement

Les LLM (grands modèles linguistiques en Français), ont fait leur apparition auprès du grand publique lors du lancement 
officiel de ChatGPT, le 30 Novembre 2022.
En moins d'une semaine, l'application qui est capable de répondre à tout et à tout le monde, à réussit à attirer ses 
premiers millions d'utilisateurs. Dés lors, en Janvier 2023, soit 2 mois après son lancement, ChatGPT à dépasser les 
100 millions d'utilisateurs, devenant de ce fait, la 2éme application numérique a connaitre la croissance la plus rapide 
de l'histoire de l'informatique, devançant de loin TikTok, Facebook et Instagram.

![image](https://www.visualcapitalist.com/wp-content/uploads/2023/07/CP_Threads-Fastest-100-Million.jpg)
source: https://www.visualcapitalist.com/threads-100-million-users/

Dés lors ChatGPT a mit en lumière les LLM auprès du grand publique, laissant libre cours à toutes sortes d'affabulations 
(exemple: l'ia va nous remplacer) ou sonnette d'alarmes sur le contenue des réponses (exemple: comment créer une bombe).

Pour ce qui est des affabulations, je vous invite à prendre connaissance des interviews du cocréateur de Siri ainsi que 
de ses livres à savoir; Luc Julia. Pour ce qui est de la sonnette d'alarme, je vous invite à poursuivre le contenu et à 
nous plonger dans le contenu de ce codelab.
Depuis ce lancement, les géants de la tech n'ont cessé de redoubler d'effort dans la course à l'IA, dépassant de loin 
chatgpt

![image](https://www.visualcapitalist.com/wp-content/uploads/2024/12/Growth-of-Big-Tech-Firms_WEB.jpg)
source: https://www.visualcapitalist.com/charted-the-growth-of-big-tech-since-chatgpts-launch/

## Intelligence Artificielle, réseaux neuronaux et LLM

Dans les médias, il n'est pas rare de lire différents termes pour parler spécifiquement d'intelligence artificielle.  
Certains utiliseront le terme réseaux neuronaux, d'autre le terme LLM ou tout simplement l'intelligence artificielle; 
cependant ces 3 termes représentent différentes facettes d'un paysage plus vaste d'apprentissage automatique et 
d'intelligence computationnelle. Tentons d'appliquer une distinction sur chacun de ces 3 termes:


IA:
L'intelligence artificielle ou Intelligence Augmenter pour d'autre est, par essence, un domaine multidisciplinaire 
visant à créer des systèmes capables d'effectuer des tâches qui nécessiteraient normalement l'intelligence humaine. 
Dans ces taches ont retrouve la résolution de problèmes, la perception ainsi que la compréhension du langage.
L'IA correspond à un large éventail de technologies, de méthodologies et des systèmes basés sur des règles aux 
algorithmes d'apprentissage automatique, servant de terme générique à de multiples approches pour parvenir à l'intelligence artificielle.

réseaux neuronaux:
Cette partie de l'intelligence artificielle s'inspire du fonctionnement du cerveau humain. Les réseaux neuronaux, 
sont des modèles informatiques conçu pour reconnaitre des schémas et d'appliquer des décisions suivant les données 
qu'ils traitent. Ils peuvent parfois être simple (on parlera alors de réseaux neurones superficiels)ou d'autre fois 
complexes (là on dira que se sont des réseaux neuronaux profonds).
Dans tous les cas, les réseaux neuronaux forment la base essentielle de nombreuses applications contemporaines 
d’intelligence artificielle, telles que la reconnaissance d’images, le traitement automatique du langage naturel et la 
conduite autonome de véhicules.

LLM:
Pour faire simple, les LLM (ou grand modèles de langage) sont un type spécifique de réseau neuronal. Ils se basent sur 
des formes avancées de réseaux neurones, comme les modèles transformateurs, pour comprendre et produire du textes a 
partir des données d'entraînement. Leur force résident dans la gestion des taches linguistiques, allant de la simple 
saisie de texte, à la synthèse rédactionnel d'un document de centaines de pages sans dénaturer l'idée principal.

![image](https://i0.wp.com/www.phdata.io/wp-content/uploads/2024/10/article-image1-6.png)


## Les Transformers: origines et architecture:
Là on ne va pas parler des films de Michael Bay, mais on va continuer à parler d'IA.

L'architecture du transformateur a été introduite dans un article scientifique intitulé "Attention is All You Need", 
publié en 2017 par une équipe de Google Brain. l'article présentait une approche innovante pour les tâches de 
traitement automatique du langage naturel (TALN), en faisant le choix de s’éloigner des modèles traditionnels qui 
reposaient principalement sur les réseaux neuronaux récurrents (RNN) et convolutifs (CNN).

wip ...
